# Mini-Project for Fundamentals of Machine Learning Course
![background](./materials/ai_wp.jpg)
This repository contains the code and data for a mini-project on facial expression recognition using machine learning algorithms.

## üìë Project Policy
- Team: group should consist of 3-4 students.

    |No.| Student Name               | Student ID |
    | --| ---------------------------| ---------- |
    | 1 | Tr·∫ßn Anh Qu√¢n              | 21110374   |
    | 2 | Tr·∫ßn Tr·ªçng Ph√∫c            | 21110372   |
    | 3 | Tr·∫ßn Xu√¢n Th·∫Øng            | 21110390   |
    | 4 | T∆∞·ªüng Ho√†ng Ng·ªçc Tuy·ªÅn     | 21110444   |

- The submission deadline is strict: **11:59 PM** on **June 22nd, 2024**. Commits pushed after this deadline will not be considered.

## üì¶ Project Structure

The repository is organized into the following directories:

- **/data**: This directory contains the facial expression dataset. You'll need to download the dataset and place it here before running the notebooks. (Download link provided below)
- **/notebooks**: This directory contains the Jupyter notebook ```EDA.ipynb```. This notebook guides you through exploratory data analysis (EDA) and classification tasks.

## ‚öôÔ∏è Usage

This project is designed to be completed in the following steps:

1. **Fork the Project**: Click on the ```Fork``` button on the top right corner of this repository, this will create a copy of the repository in your own GitHub account. Complete the table at the top by entering your team member names.

2. **Download the Dataset**: Download the facial expression dataset from the following [link](https://mega.nz/file/foM2wDaa#GPGyspdUB2WV-fATL-ZvYj3i4FqgbVKyct413gxg3rE) and place it in the **/data** directory:

3. **Complete the Tasks**: Open the ```notebooks/EDA.ipynb``` notebook in your Jupyter Notebook environment. The notebook is designed to guide you through various tasks, including:
    
    1. Prerequisite
    2. Principle Component Analysis
    3. Image Classification
    4. Evaluating Classification Performance 
To include this table and the conclusions in your README on GitHub, you can format the table in Markdown. Here is the Markdown version of your table and the conclusions:

### Summary of Model Performance

| Model                             | Accuracy | Macro Avg Precision | Macro Avg Recall | Macro Avg F1-Score | Weighted Avg Precision | Weighted Avg Recall | Weighted Avg F1-Score |
|-----------------------------------|----------|----------------------|------------------|---------------------|------------------------|---------------------|------------------------|
| Decision Tree (Original)          | 0.3165   | 0.32                 | 0.26             | 0.26                | 0.32                   | 0.32                | 0.30                   |
| Decision Tree (PCA)               | 0.3034   | 0.30                 | 0.25             | 0.25                | 0.29                   | 0.30                | 0.29                   |
| Logistic Regression (Original)    | 0.3717   | 0.44                 | 0.30             | 0.30                | 0.36                   | 0.37                | 0.35                   |
| Logistic Regression (PCA)         | 0.3717   | 0.30                 | 0.30             | 0.28                | 0.35                   | 0.37                | 0.34                   |
| K-Nearest Neighbors (Original)    | 0.3502   | 0.33                 | 0.32             | 0.32                | 0.35                   | 0.35                | 0.35                   |
| K-Nearest Neighbors (PCA)         | 0.3611   | 0.34                 | 0.33             | 0.33                | 0.36                   | 0.36                | 0.35                   |
| Multilayer Perceptron (Original)  | 0.4249   | 0.41                 | 0.40             | 0.41                | 0.42                   | 0.42                | 0.42                   |
| Multilayer Perceptron (PCA)       | 0.4093   | 0.38                 | 0.39             | 0.38                | 0.41                   | 0.41                | 0.41                   |

### So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh ph√¢n lo·∫°i kh√°c nhau

Ch√∫ng ta s·∫Ω so s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh ph√¢n lo·∫°i kh√°c nhau s·ª≠ d·ª•ng c√°c s·ªë li·ªáu: ƒë·ªô ch√≠nh x√°c, ƒë·ªô ch√≠nh x√°c, kh·∫£ nƒÉng thu h·ªìi v√† ƒëi·ªÉm F1. M·ª•c ti√™u l√† x√°c ƒë·ªãnh m√¥ h√¨nh n√†o ho·∫°t ƒë·ªông t·ªët nh·∫•t v√† lo·∫°i c·∫£m x√∫c n√†o ƒë∆∞·ª£c d·ª± ƒëo√°n ch√≠nh x√°c nh·∫•t v√† lo·∫°i c·∫£m x√∫c n√†o m√¥ h√¨nh m·∫Øc nhi·ªÅu l·ªói nh·∫•t.

#### ƒê·ªô ch√≠nh x√°c (Accuracy)
ƒê·ªô ch√≠nh x√°c ƒëo l∆∞·ªùng ƒë·ªô ƒë√∫ng ƒë·∫Øn t·ªïng th·ªÉ c·ªßa m√¥ h√¨nh. D∆∞·ªõi ƒë√¢y l√† ƒë·ªô ch√≠nh x√°c c·ªßa t·ª´ng m√¥ h√¨nh:
- Decision Tree (D·ªØ li·ªáu g·ªëc): 0.3165
- Decision Tree (D·ªØ li·ªáu PCA): 0.3034
- Logistic Regression (D·ªØ li·ªáu g·ªëc): 0.3717
- Logistic Regression (D·ªØ li·ªáu PCA): 0.3717
- K-Nearest Neighbors (D·ªØ li·ªáu g·ªëc): 0.3502
- K-Nearest Neighbors (D·ªØ li·ªáu PCA): 0.3611
- Multilayer Perceptron (D·ªØ li·ªáu g·ªëc): 0.4249
- Multilayer Perceptron (D·ªØ li·ªáu PCA): 0.4093

M√¥ h√¨nh Multilayer Perceptron (MLP) tr√™n d·ªØ li·ªáu g·ªëc c√≥ ƒë·ªô ch√≠nh x√°c cao nh·∫•t (0.4249), cho th·∫•y n√≥ d·ª± ƒëo√°n ƒë√∫ng nh√£n nhi·ªÅu h∆°n so v·ªõi c√°c m√¥ h√¨nh kh√°c.

#### ƒê·ªô ch√≠nh x√°c (Precision)
ƒê·ªô ch√≠nh x√°c ƒëo l∆∞·ªùng bao nhi√™u trong s·ªë c√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c d·ª± ƒëo√°n l√† d∆∞∆°ng t√≠nh th·ª±c s·ª± l√† d∆∞∆°ng t√≠nh. D∆∞·ªõi ƒë√¢y l√† ƒë·ªô ch√≠nh x√°c trung b√¨nh c·ªßa c√°c m√¥ h√¨nh:
- Decision Tree (D·ªØ li·ªáu g·ªëc): 0.32
- Decision Tree (D·ªØ li·ªáu PCA): 0.30
- Logistic Regression (D·ªØ li·ªáu g·ªëc): 0.44
- Logistic Regression (D·ªØ li·ªáu PCA): 0.30
- K-Nearest Neighbors (D·ªØ li·ªáu g·ªëc): 0.33
- K-Nearest Neighbors (D·ªØ li·ªáu PCA): 0.34
- Multilayer Perceptron (D·ªØ li·ªáu g·ªëc): 0.41
- Multilayer Perceptron (D·ªØ li·ªáu PCA): 0.38

M√¥ h√¨nh Logistic Regression tr√™n d·ªØ li·ªáu g·ªëc c√≥ ƒë·ªô ch√≠nh x√°c trung b√¨nh cao nh·∫•t (0.44), cho th·∫•y n√≥ d·ª± ƒëo√°n c√°c tr∆∞·ªùng h·ª£p d∆∞∆°ng t√≠nh ch√≠nh x√°c h∆°n.

#### Thu h·ªìi (Recall)
Kh·∫£ nƒÉng thu h·ªìi ƒëo l∆∞·ªùng bao nhi√™u trong s·ªë c√°c tr∆∞·ªùng h·ª£p d∆∞∆°ng t√≠nh th·ª±c s·ª± ƒë∆∞·ª£c m√¥ h√¨nh ph√°t hi·ªán. D∆∞·ªõi ƒë√¢y l√† kh·∫£ nƒÉng thu h·ªìi trung b√¨nh c·ªßa c√°c m√¥ h√¨nh:
- Decision Tree (D·ªØ li·ªáu g·ªëc): 0.26
- Decision Tree (D·ªØ li·ªáu PCA): 0.25
- Logistic Regression (D·ªØ li·ªáu g·ªëc): 0.30
- Logistic Regression (D·ªØ li·ªáu PCA): 0.30
- K-Nearest Neighbors (D·ªØ li·ªáu g·ªëc): 0.32
- K-Nearest Neighbors (D·ªØ li·ªáu PCA): 0.33
- Multilayer Perceptron (D·ªØ li·ªáu g·ªëc): 0.40
- Multilayer Perceptron (D·ªØ li·ªáu PCA): 0.39

M√¥ h√¨nh Multilayer Perceptron tr√™n d·ªØ li·ªáu g·ªëc c√≥ kh·∫£ nƒÉng thu h·ªìi trung b√¨nh cao nh·∫•t (0.40), cho th·∫•y n√≥ ph√°t hi·ªán ƒë∆∞·ª£c nhi·ªÅu tr∆∞·ªùng h·ª£p d∆∞∆°ng t√≠nh h∆°n.

#### F1 (F1-Score)
F1- score l√† trung b√¨nh ƒëi·ªÅu h√≤a gi·ªØa ƒë·ªô ch√≠nh x√°c v√† kh·∫£ nƒÉng thu h·ªìi. D∆∞·ªõi ƒë√¢y l√† ƒëi·ªÉm F1 trung b√¨nh c·ªßa c√°c m√¥ h√¨nh:
- Decision Tree (D·ªØ li·ªáu g·ªëc): 0.26
- Decision Tree (D·ªØ li·ªáu PCA): 0.25
- Logistic Regression (D·ªØ li·ªáu g·ªëc): 0.30
- Logistic Regression (D·ªØ li·ªáu PCA): 0.28
- K-Nearest Neighbors (D·ªØ li·ªáu g·ªëc): 0.32
- K-Nearest Neighbors (D·ªØ li·ªáu PCA): 0.33
- Multilayer Perceptron (D·ªØ li·ªáu g·ªëc): 0.41
- Multilayer Perceptron (D·ªØ li·ªáu PCA): 0.38

M√¥ h√¨nh Multilayer Perceptron tr√™n d·ªØ li·ªáu g·ªëc c√≥ ƒëi·ªÉm F1 trung b√¨nh cao nh·∫•t (0.41), cho th·∫•y s·ª± c√¢n b·∫±ng t·ªët nh·∫•t gi·ªØa ƒë·ªô ch√≠nh x√°c v√† kh·∫£ nƒÉng thu h·ªìi.

#### Nh·∫≠n x√©t t·ª´ Confusion Matrix
D∆∞·ªõi ƒë√¢y l√† nh·∫≠n x√©t t·ª´ c√°c confusion matrix c·ªßa t·ª´ng m√¥ h√¨nh:

**Decision Tree:**
- D·ªØ li·ªáu g·ªëc: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.53) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.02).
- D·ªØ li·ªáu PCA: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.59) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.06).

**Logistic Regression:**
- D·ªØ li·ªáu g·ªëc: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.67) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.02).
- D·ªØ li·ªáu PCA: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.70) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.00).

**K-Nearest Neighbors:**
- D·ªØ li·ªáu g·ªëc: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.51) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.23).
- D·ªØ li·ªáu PCA: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.56) nh∆∞ng m·∫Øc l·ªói nhi·ªÅu nh·∫•t cho nh√£n 1 (recall 0.25).

**Multilayer Perceptron:**
- D·ªØ li·ªáu g·ªëc: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.58) v√† 5 (recall 0.54), nh∆∞ng m·∫Øc l·ªói √≠t nh·∫•t cho nh√£n 1 (recall 0.35).
- D·ªØ li·ªáu PCA: M√¥ h√¨nh n√†y ho·∫°t ƒë·ªông t·ªët nh·∫•t cho nh√£n 3 (recall 0.60) nh∆∞ng m·∫Øc l·ªói √≠t nh·∫•t cho
    Make sure to run all the code cells in the ```EDA.ipynb``` notebook and ensure they produce output before committing and pushing your changes.

5. **Commit and Push Your Changes**: Once you've completed the tasks outlined in the notebook, commit your changes to your local repository and push them to your forked repository on GitHub.


Feel free to modify and extend the notebook to explore further aspects of the data and experiment with different algorithms. Good luck.
